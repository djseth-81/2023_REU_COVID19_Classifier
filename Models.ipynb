{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Authors: Ray Donner and Seth Johnson\n",
    "- Date: May 25, 2023\n",
    "- Content: This file is a conglomerate of all the machine learning algorithms that we run and collect data on. This will include the following algorithms:\n",
    "    - Categorical Naive-Bayes\n",
    "    - Support Vector Machines\n",
    "    - Decision Trees\n",
    "    - Neural Network\n",
    "    - Convolutional Neural Network\n",
    "- The goal is to analyze this with our new dataset COVID19_APK_Data_06-2023.csv and compare train/test performace, as well as provide statistical analysis to compare COVIDMalware.pdf dataset to ours."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN ME FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sdj81/PyWorkspace/2023_REU_Workspace\n",
      "### CONSOLE: Preprocessing complete...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "### Package handling\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import pylab as pl\n",
    "import random\n",
    "from pprint import pprint\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\"\"\"\n",
    "### Site for Tensorflow reference: https://www.tensorflow.org/guide/distributed_training\n",
    "\"\"\"\n",
    "\n",
    "models = {\n",
    "    \"Categorical NB\": {\n",
    "        \"Epoch_duration\": [20],\n",
    "        \"duration\": 1,\n",
    "        \"history\": 0 # model.fit().history.items()\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"Epoch_duration\": [20],\n",
    "        \"duration\": 1,\n",
    "        \"history\": 0\n",
    "    },\n",
    "    \"dTree\": {\n",
    "        \"Epoch_duration\": [20],\n",
    "        \"duration\": 1,\n",
    "        \"history\": 0\n",
    "    },\n",
    "    \"DNN\": {\n",
    "        \"Epoch_duration\": [20],\n",
    "        \"duration\": 1,\n",
    "        \"history\": 0\n",
    "    },\n",
    "    \"CNN\": {\n",
    "        \"Epoch_duration\": [20],\n",
    "        \"duration\": 1,\n",
    "        \"history\": 0\n",
    "    },\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "### Preprocessing\n",
    "\"\"\"\n",
    "\n",
    "keys = [] # Lables of CSV data that is NOT the permissions requested by a given APK file\n",
    "benignSpread = [] # permission spread requested by benign APK files\n",
    "maliciousSpread = [] # permission spread requested by APK files flagged by AV software\n",
    "\n",
    "print(os.getcwd()) # Displaying script's CWD\n",
    "\n",
    "apkData = pd.read_csv(\"COVID19_APK_Data_06-2023.csv\") # Calling CSV and filling DataFrame (DF)\n",
    "\n",
    "\"\"\"\n",
    "### Scraping our CSV's DF\n",
    "\"\"\"\n",
    "# Building keys array for parsinng reference later\n",
    "for i in range(7):\n",
    "    keys.append(apkData.keys()[i])\n",
    "\n",
    "# print(keys)\n",
    "\n",
    "permSpread = apkData.loc[0].keys().drop(i for i in keys).values # Key values for the permissions requested by a given APK file\n",
    "apks = apkData[\"APK File\"].values # Pulling APK files to correlate labels\n",
    "labels = apkData[\"AV Rank\"].values # Referring to a specific column in a DF\n",
    "perms = [apkData.loc[i].drop((i for i in keys)).values for i in range(len(apkData))] # How would I parse this to exclude the first 7 columns?\n",
    "\n",
    "totalAPKs = len(labels)\n",
    "totalBadAPKs = sum([1 if item > 0 else 0 for item in labels])\n",
    "\n",
    "# print(f\"length of apks array: {len(apks)}\")\n",
    "# print(f\"length of perms array: {len(perms)}\")\n",
    "# print(f\"length of labels array: {len(labels)}\")\n",
    "\n",
    "# print(f\"length of permissions in subarray: {len(perms[0])}\")\n",
    "# print(permSpread)\n",
    "# print(f\"length of permSpread: {len(permSpread)}\")\n",
    "# print(f\"total length of labels: {len(apkData.keys())}\")\n",
    "\n",
    "# Writes a structured output to a file of all data parsed out of csv's DF\n",
    "# with open(\"stupid.txt\", \"w\") as outFile:\n",
    "#     for i in range(len(apks)):\n",
    "#         outFile.write(\"Application: \" + apkData.loc[i].loc[\"Application Name\"] + \"\\n\")\n",
    "#         outFile.write(\"Package: \" + apkData.loc[i][\"Package Name\"] + \"\\n\")\n",
    "#         outFile.write(f\"APK File: {apks[i]}\" + \"\\n\")\n",
    "#         outFile.write(f\"AV Rank: {labels[i]}\" + \"\\n\")\n",
    "#         outFile.write(f\"Total Permissions Requested: {sum(perms[i])}\" + \"\\n\")\n",
    "#         outFile.write(f\"Permission Spread: {perms[i]}\" + \"\\n\")\n",
    "#         outFile.write(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "apps = {}\n",
    "\n",
    "# pprint(apps)\n",
    "\n",
    "print(\"### CONSOLE: Preprocessing complete...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics for our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - Percentage of malicious APKs wrt to dataset\n",
    "# - Percentage of APKs that failed analysis\n",
    "# - percentage of apps that are malicious\n",
    "# - percentage of apps that failed analysis\n",
    "# - Std Dev, Std Err to compare my processed data with the data provided by COVIDMalware.pdf\n",
    "#      - might be useful to includ metric of apks that failed analysis\n",
    "#      - this can help confirm that what I did was right\n",
    "#      - Check Stats 305 stuff to provide formulas and context for these values\n",
    "# - normalize, proportionalize data to plot\n",
    "# - Plot the data I've collected\n",
    "#   - Compare total requested per apk\n",
    "#   - compare types of perms requested per apk\n",
    "#   - Compare how many apps requested how many permissions --> TODO\n",
    "#   - F.E: Compare benign vs malicious\n",
    "\n",
    "\"\"\"\n",
    "### Plotting the total permissions requested by a given apk, organized based off an AV rank > 0\n",
    "\"\"\"\n",
    "\n",
    "# Sorting the permission spread between malicious and benign\n",
    "for i in range(len(apks)):\n",
    "    if labels[i] > 0:\n",
    "        # print(f\"APK File {apks[i]} is malicious!\")\n",
    "        maliciousSpread.append(perms[i])\n",
    "    else:\n",
    "        benignSpread.append(perms[i])\n",
    "\n",
    "maliciousSpread_sums = [sum(i) for i in maliciousSpread]\n",
    "benignSpread_sums = [sum(i) for i in benignSpread]\n",
    "\n",
    "# plt.bar([i for i in range(len(benignSpread_sums))], benignSpread_sums, label=\"AV Rank = 0\")\n",
    "# plt.bar([i for i in range(len(maliciousSpread_sums))], maliciousSpread_sums,label=\"AV Rank > 0\")\n",
    "# plt.xlabel(\"APK File\")\n",
    "# plt.ylabel(\"Quantity of requested permissions\")\n",
    "# plt.title(\"Total number of permissions requested for a given APK file.\")\n",
    "# plt.legend()\n",
    "# plt.savefig(\"TotalPermissionsGraphed.png\", dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "\"\"\"\n",
    "### Plotting how many apps requested a given quantity of permissions\n",
    "\"\"\"\n",
    "print(f\"The most permissions requested by any given Malicious APK file: {max(maliciousSpread_sums)}\")\n",
    "print(f\"The most permissions requested by any given benign APK file: {max(benignSpread_sums)}\")\n",
    "\n",
    "x = [i for i in range(max(maliciousSpread_sums) + 1)] if maliciousSpread_sums > benignSpread_sums else [i for i in range(max(benignSpread_sums) + 1)]\n",
    "# print(f\"Array of quantity of permissions: {x}\")\n",
    "\n",
    "yBenign = [0 for _ in range(len(x))]\n",
    "yMalicious = [0 for _ in range(len(x))]\n",
    "\n",
    "for i in benignSpread_sums:\n",
    "    # print(f\"sum of permSread for Bening apks: {i}\")\n",
    "    # print(f\"x index: {x[i]}\")\n",
    "    yBenign[i] += 1\n",
    "\n",
    "for i in maliciousSpread_sums:\n",
    "    # print(f\"sum of permSread for Malicious apks: {i}\")\n",
    "    # print(f\"x index: {x[i]}\")\n",
    "    yMalicious[i] += 1\n",
    "\n",
    "print(yBenign)\n",
    "# print(yMalicious)\n",
    "\n",
    "plt.bar(xBenign, yBenign, label=\"AV Rank = 0\")\n",
    "plt.bar(xMalicious, yMalicious, label=\"AV Rank > 0\")\n",
    "plt.title(\"Quantity of APK Files requesting a given quantity of permissions\")\n",
    "plt.xlabel(\"Quantity of permissions requested per APK file\")\n",
    "plt.ylabel(\"Quantity of APK files\")\n",
    "plt.legend()\n",
    "plt.savefig(\"FreqPermSpreadTotal.png\", dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "# benignSpreadSums = []\n",
    "# for perm in permSpread[:20]:\n",
    "#     benignSpreadSums.append(apkData[perm].sum())\n",
    "\n",
    "# plt.barh(permSpread[:20], benignSpreadSums)\n",
    "# plt.ylabel(\"Permissions requested by APK\")\n",
    "# plt.xlabel(\"Frequency of APKs\")\n",
    "# plt.savefig(\"PermSpread.png\", dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "# OR\n",
    "# apkData[\"Total permission requests\"].plot(kind=\"hist\")\n",
    "\n",
    "# How many APKs are malicious?\n",
    "print(f\"We analyzed {totalAPKs} APKs\")\n",
    "print(f\"Out of that, {totalBadAPKs} were flagged as malicious. This is according to the dataset provided by Wang et al 2021.\")\n",
    "print(f\"Which means about {((totalBadAPKs / totalAPKs) * 100):.2f}% of all analyzed APKs are labeled as malicious.\")\n",
    "\n",
    "# print(features_df)\n",
    "# print(label_df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit Learn prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Package handling\n",
    "\"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB  # WE WILL NOT BE USING GAUSSIAN N-B\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC # importing the Classifier module specifically\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Package handling\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Embedding,\n",
    "    LSTM\n",
    ")\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import utils\n",
    "from keras.models import Sequential\n",
    "\n",
    "\"\"\"\n",
    "### Can we use the GPU?\n",
    "\"\"\"\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print(f'GPU installed. Good Job!\\nGPU Device: {tf.test.gpu_device_name()}')\n",
    "else:\n",
    "    print(\" No GPU found that can run TF.\")\n",
    "\n",
    "\"\"\"\n",
    "### Overridden callback class \"timer\" for catching epoch/total time\n",
    "\"\"\"\n",
    "class timer(keras.callbacks.callbacks):\n",
    "    import time\n",
    "    def __init__(self): # initalized callback\n",
    "        super(timer, self).__init__() # remember inheritance from OOP\n",
    "\n",
    "    # training methods\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_train=time.time()\n",
    "    def on_train_end(self, logs=None):\n",
    "        stop_train = time.time()\n",
    "        train_duration = stop_train - start_train\n",
    "        # Calculates metrics\n",
    "        tr_hours = tr_duration // 3600\n",
    "        tr_minutes = (tr_duration - (hours * 3600)) // 60\n",
    "        tr_seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
    "        # Generates message of string\n",
    "        msg = f\"Elapsed time: {str(tr_hours)}:{str(tr_minutes)}:{str(tr_seconds)}\"\n",
    "        print(msg)\n",
    "    \n",
    "    # batch training methods <-- might not need this\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        pass\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    # epoch methods\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_epoch = time.time()\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        stop_epoch = time.time()\n",
    "        epoch_duration = stop_epoch - start_epoch\n",
    "        msg = f\"Epoch {epoch + 1} trained for {epoch_duration} seconds\"\n",
    "        print(msg)\n",
    "\n",
    "    # prediction methods <-- this might be useful in the long run during CrossVal\n",
    "    def on_predict_begin(self, logs=None):\n",
    "        pass\n",
    "    def on_predict_end(self, logs=None):\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Visualizing model performace\n",
    "- I like the idea of visualizing our confusion matrix\n",
    "  - use that to also visualize performance per K-fold iteration\n",
    "- compare average values across all models\n",
    "  - Train/Test: F1, accuracy, Recall, percision, time\n",
    "- I can't remember the how else Dr Perez wants to compare data\n",
    "\"\"\"\n",
    "for val, data in history.history.items():\n",
    "  plt.plot(data)\n",
    "  plt.title(val)\n",
    "  plt.show()\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
